================================
Language Model Fine-tuning
Job ID: 75240
Model: mistral
Selection: random
Data File: Data_Processing/CAI/data/constitutional_training_data_mistral.jsonl
Node: pax007
Started: Mon Nov 10 03:49:20 PM EST 2025
================================

Working Directory set to: /cluster/home/supadh03/CAI/Constituitional-AI
Output directory is: models/finetuned
================================================================================
Constitutional AI Fine-Tuning
================================================================================
Base model: mistralai/Mistral-7B-Instruct-v0.3
Selection method: random
Data file: Data_Processing/CAI/data/constitutional_training_data_mistral.jsonl
Output directory: models/finetuned/mistral_random
Validation size: 79

Loading training data...
Loaded 979 examples
Loading existing split from models/finetuned/train_val_split.json...
✓ Using seed 42
Train: 900 examples
Validation: 79 examples
✓ Validation prompts verified consistent across datasets

Preparing training data...
✓ Training dataset: 900 examples
✓ Validation dataset: 79 examples

Loading mistralai/Mistral-7B-Instruct-v0.3...
✓ CUDA available
✓ GPU: NVIDIA A100 80GB PCIe

✓ Model loaded: cuda:0
✓ Parameters: 7.25B

Tokenizing data...
✓ Tokenization complete

--- Callback: Storing model and tokenizer references. ---
================================================================================
Starting Training
================================================================================

{'loss': 2.0401, 'grad_norm': 133.125, 'learning_rate': 4.0397350993377485e-07, 'epoch': 0.89}
{'eval_loss': 2.6477043628692627, 'eval_runtime': 7.4749, 'eval_samples_per_second': 10.569, 'eval_steps_per_second': 10.569, 'epoch': 0.89}
--- New best model! Eval loss: 2.6477043628692627 ---
--- ERROR: Callback could not find model or tokenizer to save. ---
{'loss': 1.6937, 'grad_norm': 129.25, 'learning_rate': 2.3841059602649005e-07, 'epoch': 1.76}
{'eval_loss': 1.895588994026184, 'eval_runtime': 7.4572, 'eval_samples_per_second': 10.594, 'eval_steps_per_second': 10.594, 'epoch': 1.76}
--- New best model! Eval loss: 1.895588994026184 ---
--- ERROR: Callback could not find model or tokenizer to save. ---
{'loss': 0.7974, 'grad_norm': 29.140625, 'learning_rate': 7.284768211920529e-08, 'epoch': 2.64}
{'eval_loss': 1.578827977180481, 'eval_runtime': 7.4515, 'eval_samples_per_second': 10.602, 'eval_steps_per_second': 10.602, 'epoch': 2.64}
--- New best model! Eval loss: 1.578827977180481 ---
--- ERROR: Callback could not find model or tokenizer to save. ---
{'train_runtime': 986.7457, 'train_samples_per_second': 2.736, 'train_steps_per_second': 0.173, 'train_loss': 1.3905434636344687, 'epoch': 3.0}

================================================================================
Training Complete!
================================================================================

Saving model to models/finetuned/mistral_random...
✓ Model saved to models/finetuned/mistral_random
✓ Training info saved

================================================================================
Fine-tuning Complete!
================================================================================

================================
Job completed: Mon Nov 10 04:06:35 PM EST 2025
================================
