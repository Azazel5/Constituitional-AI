## Constituitional AI, revisited


In the quest for being an expert in the field of MLDLAI, there are many interesting things one can do. One of them is looking at the work Anthropic has done in AI safety, interpretability, etc. Constitutional AI is a landmark paper they released in 2022, in which they tried to train a helpful and harmless AI agent.

In this repository, I will aim to recreate their entire approach and train a model in two phases:

1. Supervised CAI (Constitutional AI)
2. RLAIF (RL through AI Feedback)


This is phase one


## Constitutional AI, explored


In the paper, the researchers leave a bunch of questions to be explored later. Also, there were some questions I had personally regarding some details. These are the ones I will try to address with this repository. Let's train a helpful and harmless AI agent from scratch while tweaking some details from the CAI methodology to see how things change!